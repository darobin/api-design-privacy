<!DOCTYPE html>
<html xmlns='http://www.w3.org/1999/xhtml' lang='en'>
  <head>
    <meta charset='utf-8'/>
    <title>Privacy by Design in APIs</title>
    <script src='http://dvcs.w3.org/hg/respec2/rawfile/tip/js/profiles/w3c-common.js'></script>
    <script class='remove'>
      var respecConfig = {
          specStatus:           "draft-finding"
      ,   shortName:            "privacy-by-design-in-apis"
      //,  publishDate:  "2009-08-06"
      // ,   copyrightStart: "2011"
      // ,   previousPublishDate:  "2011-04-28"
      // ,   previousMaturity:  "draft-finding"
      ,   edDraftURI:           "http://darobin.github.com/api-design-privacy/api-design-privacy.html"
      ,   extraCSS:             ["http://dev.w3.org/2009/dap/ReSpec.js/css/respec.css"]
      ,   editors:  [
              { name: "Robin Berjon", url: "http://berjon.com/", company: "freelance" }
          ,   { name: "Daniel Appelquist", url: "http://www.torgo.com/" }
          ]
      ,   wg:           "Technical Architecture Group"
      ,   wgURI:        "http://www.w3.org/2001/tag/"
      ,   wgPublicList: "www-tag"
      ,   wgPatentURI:  ""
      };
    </script>
  </head>
  <body>
    <section id='abstract'>
      <p>
        This document provides some background on the threats to users' privacy that Javascript APIs help create
        on the Web, and provides some strategies to mitigate such threats at the API design level. Its primary
        audience is therefore people involved in the definition and implementation of such APIs.
      </p>
    </section>
    <section id='sotd'>
      <p>
        This document is a draft TAG finding, and as such has no official standing whatsoever.
      </p>
      <p>
        This document is a work in progress from the
        <a href="http://www.w3.org/2001/tag/"><acronym title="World Wide Web Consortium">W3C</acronym> 
        Technical Architecture Group (TAG)</a>. <a href="/2001/tag/findings">Additional TAG findings</a>, both
        accepted and in draft state, may also be available. The TAG may incorporate this and other findings 
        into future versions of the [[AWWW]].  Please send comments on this finding to the publicly archived 
        TAG mailing list <a href="mailto:www-tag@w3.org">www-tag@w3.org</a> 
        (<a href="http://lists.w3.org/Archives/Public/www-tag/">archive</a>).
      </p>
    </section>
    <section>
      <h2>Introduction</h2>
      <p>
        User privacy is a core feature of the Web. As the Web continues its evolution into a powerful application
        platform, an increasing number of its additional abilities risk compromising user privacy unless they
        are specifically created to promote it. While potentially present in all aspects of the Web platform,
        this issue is particularly salient when it comes to Javascript APIs since they comprise one of the
        most frequent and natural extensibility point for powerful features that can be misused, and that are
        hard to mitigate against.
      </p>
      <p>
        This leads to a strong requirement on these APIs to take user privacy into account. This, in turn, imposes
        design constraints that are different from those found in more traditional applications programming which
        entails that experience with APIs designed for the latter seldom applies in full and needs to be revisited.
      </p>
      <p>
        In this document we consider only those aspects of privacy and APIs that can be mitigated by API designers,
        notably providing more information than is necessary for a given operation, not making it possible for the
        user to control what information is being shared, and user fingerprinting. Conversely we do not cover other
        privacy attacks such as tricking the user into providing information or maliciously using collected information
        in ways that were not agreed to by the user. We have chosen this focus because well-designed APIs from the 
        privacy standpoint should provide a solid foundation for better user privacy in general, because they can help
        address the problem at the root, and because we feel that they form a coherent whole.
      </p>
      <section>
        <h2>Privacy and Security</h2>
        <p>
          It is common for discussions of these privacy issues to raise objections that they are a matter of security
          and not privacy. Conversely, if raised as matters of security, objections will surface according to which
          they constitute a specifically privacy problem.
        </p>
        <p>
          It is the authors' considered opinion that this distinction is both immaterial and irrelevant. Both privacy
          and security are fundamental promises of the Web user agent; when they are broken users suffer and the Web
          dysfunctions. Providing the means to address the issues raised in this document is therefore a positive
          step forward irrespective of the way in which they are categorised.
        </p>
      </section>
    </section>
    <section>
      <h2>Privacy by Design</h2>
      <p>
        Privacy by design is a design approach that takes malicious practices for granted and endeavours to prevent and
        mitigate them from the ground up by applying specific strategies to the creation of software (in this document's
        scope specifically of APIs).
      </p>
      <p>
        It is particularly important in privacy by design that users be exposed to as few direct privacy decisions as
        possible. Notably, it should never be assumed that users can be “educated” into making correct privacy decisions.
        The reason for this is that user typically interact with their user agent in order to accomplish a specific task.
        Anything that interrupts the flow of that task's realisation is likely to only be given as cursory a thought
        as possible. Therefore, requiring users to make privacy decisions whilst in the middle of accomplishing a task
        is a recipe for poor decisions.
      </p>
      <p>
        There are two primary issues that privacy by design seeks to address.
      </p>
      <section>
        <h2>Poor Information Scoping</h2>
        <p>
          In order to accomplish a given operation, a Web application may legitimately require access to some of 
          the user's private information. The issue here is that in providing access to the required information
          can sometimes entail exposing a lot more information. For instance, when the user wishes to share one
          event in their calendar, the entire calendar becomes available; or where the user needs to share the
          name and email addresses of some of their contacts, the phone numbers, pictures, home addresses, etc.
          of these contacts are also returned.
        </p>
      </section>
      <section>
        <h2>User Fingerprinting</h2>
        <p>
          Users are routinely tracked across the Web through the use of cookies and other such identification
          mechanisms. In many cases, these tracking methods can be successfully mitigated by the user agent, for instance
          by only returning cookies for the top level window in the browsing context (as opposed to providing them
          for <code>iframe</code>s for instance).
        </p>
        <p>
          Fingerprinting circumvents this by looking at as many of the unique features of a user agent in order to
          ascertain its uniqueness. For instance, it may look at screen resolution, the availability of specific
          plugins, at the list of fonts that are installed on the system, the user agent string, the timezone, and
          a wealth of information that user agents tend to provide by default. Taken one by one, none of these
          data are sufficient to identify a single user, but put together they collect enough bits to narrow
          the identification down to just the one person — especially if you take into account the population 
          that visits a given site or set of sites.
        </p>
        <p>
          A very good demonstration of fingerprinting, alongside with a paper detailing the approach, are
          available from <a href='http://panopticlick.eff.org/'>Panopticlick — How Unique and Traceable is Your Browser?</a>
        </p>
      </section>
    </section>
    <!-- 
      - what is privacy by design (find nice definition of security by design)
      - save what can be from:
        - Dan's document
        - Frederick's document
      - what is fingerprinting
        - pilfer from Panopticlick
      - Mitigation strategies
        - user mediation (this seems to conflict with not involving users, but here is why not)
        - minimisation
        - action-based availability (gamepad, mouse — no enumeration–—‚)
    -->
    <section class='appendix'>
      <h2>Acknowledgments</h2>
      <p>
        In addition to the members of the TAG, the editors would like to thank the following individuals 
        for their contributions to this document:
      </p>
      <p>
        Ernesto Jiménez, Dominique Hazaël-Massieux, and Frederick Hirsch.
      </p>
    </section>
  </body>
</html>
